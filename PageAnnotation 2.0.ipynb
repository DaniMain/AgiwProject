{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lxml.html\n",
    "from lxml import etree\n",
    "import xml.etree.ElementTree as ET\n",
    "import string\n",
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def AbsolutePaths(tags):\n",
    "    tmp=''\n",
    "    for tag in tags:\n",
    "        tmp+=tag.tag+'/'\n",
    "    return str(tmp)    \n",
    "\n",
    "def xpath_generator(C):\n",
    "  X = []\n",
    "  for link in C:\n",
    "    #ritorna la get\n",
    "    link = ''.join(link)\n",
    "    link = link[:len(link)-1]    \n",
    "    response = requests.get(link)\n",
    "    #ritorna l'elemento html della pagina\n",
    "    tree = lxml.html.fromstring(response.text)\n",
    "    #ritorna la lista dei nodi foglia\n",
    "    childs = tree.xpath('//*[not(child::*)]')\n",
    "    #funzione che calcola il path assoluto radice-foglia come stringa\n",
    "    #calcolo della lista che contiene gli xpath assoluti alle foglie della pagina \n",
    "    for child in childs:\n",
    "      #ciascun elemento in X è una quadrupla (implementata come una lista di 4 elementi) formata da:\n",
    "      #url della pagina, xpath di ciascun nodo della pagina, contenuto del nodo, peso del nodo\n",
    "      xpath_element = []\n",
    "      tags = child.xpath('ancestor::node()')\n",
    "      path = AbsolutePaths(tags)\n",
    "      path += str(child.tag)\n",
    "      contenuto = child.text_content()\n",
    "      xpath_element.append(link)\n",
    "      xpath_element.append(path)\n",
    "      xpath_element.append(contenuto)\n",
    "      xpath_element.append(0)\n",
    "      X.append(xpath_element)\n",
    "  return X\n",
    "\n",
    "#Ricerca la frequenza e la frequenza del contenuto di un certo xpath\n",
    "#e la cardinalità dell'insieme di tutti i contenuti associati a quell'xpath\n",
    "def find_f(url, xpath, contenuto, lista):\n",
    "  frequenza = 1\n",
    "  f_contenuto = 1\n",
    "  #t_i è l'insieme di tutti i contenuti associati a xpath\n",
    "  t_i = [contenuto]\n",
    "  #lista dei url già visti nella ricerca\n",
    "  url_visti = []\n",
    "  url_visti.append(url)\n",
    "  for new_path in lista:\n",
    "    #se allo stesso xpath ho un contenuto diverso da quelli che già ho lo inserisco in t_i\n",
    "    if new_path[1] == xpath and new_path[2] not in t_i:\n",
    "      t_i.append(new_path[2])\n",
    "    #calcolo della frequenza e di f_contenuto\n",
    "    if new_path[0] not in url_visti:\n",
    "      if new_path[1] == xpath:\n",
    "        url_visti.append(new_path[0])\n",
    "        frequenza += 1\n",
    "        if new_path[2] == contenuto:\n",
    "          f_contenuto += 1\n",
    "  return frequenza, f_contenuto, len(t_i)\n",
    "\n",
    "#lista = [(url,xpath,contenuto,peso), (....), (....), .... ]\n",
    "def calcolo_pesi_xpath(lista, num_pagine):\n",
    "  for xpath in lista:\n",
    "    #prendo xpath\n",
    "    x = xpath[1]\n",
    "    url = xpath[0]\n",
    "    contenuto = xpath[2]\n",
    "    #calcolo la frequenza, la frequenza del contenuto e la cardinalità di t_i\n",
    "    frequenza, f_contenuto, t_i = find_f(url, x, contenuto, lista)\n",
    "    #calcolo della informatività\n",
    "    info = 1 - (f_contenuto / (num_pagine * t_i))\n",
    "    #calcolo del peso del xpath\n",
    "    peso = frequenza * info\n",
    "    #inserisco il peso nella lista\n",
    "    xpath[3] = peso\n",
    "    \n",
    "def somma_pesi_per_pagina(X):\n",
    "  url_pesi = {}\n",
    "  for e in X:\n",
    "    k = e[0]\n",
    "    if k not in url_pesi.keys():\n",
    "      url_pesi[k] = e[3]\n",
    "    else:\n",
    "      url_pesi[k] += e[3]\n",
    "  return url_pesi\n",
    "\n",
    "#Trova la pagina (ritornando il suo url) che ha massima la somma dei pesi di tutti i suoi xpath\n",
    "def find_p(X):\n",
    "  #creo un dizionario che ha come chiave l'url di una pagina e come valore la somma di tutti i pesi dei suoi xpath\n",
    "  pagine_con_pesi = somma_pesi_per_pagina(X)\n",
    "  peso_max = 0\n",
    "  pagina_max = ''\n",
    "  #ricerco la pagina che ha valore massimo nel dizionario creato precedentemente\n",
    "  for k in pagine_con_pesi.keys():\n",
    "    peso_pagina = pagine_con_pesi[k]\n",
    "#     print(k, peso_pagina)\n",
    "    if peso_pagina > peso_max:\n",
    "      pagina_max = k\n",
    "      peso_max = peso_pagina\n",
    "#   print('\\n')\n",
    "  #ritorno l'url della pagina trovata\n",
    "  return pagina_max, peso_max\n",
    "\n",
    "#Crea un dizionario con chiave xpath e valore il contenuto\n",
    "def build_dict(X, p):\n",
    "  d = {}\n",
    "  for e in X:\n",
    "    if e[0] == p:\n",
    "      if e[1] not in d:\n",
    "        xpath = e[1]\n",
    "        content = e[2]\n",
    "        d[xpath] = content\n",
    "  return d\n",
    "\n",
    "#Rimuove la pagina da X e gli xpath associati ad essa\n",
    "def remove(X, p):\n",
    "  #nuova lista da riportare\n",
    "  X1 = []\n",
    "  dict_xpath_content = build_dict(X,p)\n",
    "  for e in X:\n",
    "    #se l'xpath è contenuto in una pagina diversa da p\n",
    "    #e ha un xpath non presente in p allora lo aggiungo a X1\n",
    "    if e[0] != p and e[1] not in dict_xpath_content:\n",
    "      X1.append(e)\n",
    "  return X1\n",
    "\n",
    "# ============= MAIN =============\n",
    "def page_annotation(C, K):\n",
    "  X = xpath_generator(C)\n",
    "  print('XPath totali: ' + str(len(X)))\n",
    "  calcolo_pesi_xpath(X, len(C))\n",
    "  S = []\n",
    "  pesi = []\n",
    "  while X != [] and len(S) <= K:      \n",
    "    p, peso = find_p(X)\n",
    "    print(p)\n",
    "    S.append(p)\n",
    "    pesi.append(peso)\n",
    "    X = remove(X, p)\n",
    "  return S, X, pesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carico il set di dati che voglio analizzare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = []\n",
    "with open('rotten.csv', 'r') as file:\n",
    "    for line in file:\n",
    "        site.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209446"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del site[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104723\n",
      "104722\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "train=[]\n",
    "test=[]\n",
    "for url in site:\n",
    "    if i<(len(site)/2):\n",
    "        train.append(url)\n",
    "    else:\n",
    "        test.append(url)\n",
    "    i+=1\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prova con 100 elementi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train100 = train[:100]\n",
    "train_2_100 = train[102:202]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XPath totali: 57819\n",
      "https://www.rottentomatoes.com/m/fantastic_four\n",
      "https://www.rottentomatoes.com/m/star_wars_episode_iii_revenge_of_the_sith/pictures/\n",
      "https://www.rottentomatoes.com/m/1144992-crash/trailers/\n",
      "https://www.rottentomatoes.com/m/war_of_the_worlds\n",
      "https://www.rottentomatoes.com/m/star_wars_episode_iii_revenge_of_the_sith/trailers/\n",
      "https://www.rottentomatoes.com/m/star_wars_episode_iii_revenge_of_the_sith\n",
      "XPath rimanenti: 26\n"
     ]
    }
   ],
   "source": [
    "s1, x1, p1 = page_annotation(train100,5)\n",
    "\n",
    "#print(len(s1))\n",
    "print('XPath rimanenti: ' + str(len(x1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XPath totali: 55348\n",
      "https://www.rottentomatoes.com/m/great_raid\n",
      "https://www.rottentomatoes.com/m/aristocrats\n",
      "https://www.rottentomatoes.com/m/dukes_of_hazzard\n",
      "https://www.rottentomatoes.com/m/brothers_grimm\n",
      "https://www.rottentomatoes.com/m/deuce_bigelow_european_gigolo\n",
      "https://www.rottentomatoes.com/m/1149472-skeleton_key\n",
      "6\n",
      "XPath rimanenti: 20325\n"
     ]
    }
   ],
   "source": [
    "s2, x2, p2 = page_annotation(train_2_100,5)\n",
    "\n",
    "#print(len(s2))\n",
    "print('XPath rimanenti: ' + str(len(x2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.40146218589707894\n",
      "Recall = 0.9313222574354465\n"
     ]
    }
   ],
   "source": [
    "primo1 = p1[0]\n",
    "primo2 = p2[0]\n",
    "somma1 = 0\n",
    "somma2 = 0\n",
    "for p in p1:\n",
    "    somma1 += p\n",
    "for p in p2:\n",
    "    somma2 += p\n",
    "\n",
    "somma1 = somma1 - primo1\n",
    "somma2 = somma2 - primo2\n",
    "\n",
    "precision1 = primo1/somma1\n",
    "precision2 = primo2/somma2\n",
    "recall = primo2/primo1\n",
    "\n",
    "print('Precision = ' + str((precision1+precision2)/2))\n",
    "print('Recall = ' + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
