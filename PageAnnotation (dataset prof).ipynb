{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definizione delle funzini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lxml.html\n",
    "from lxml import etree\n",
    "import xml.etree.ElementTree as ET\n",
    "import string\n",
    "import numpy as np\n",
    "import time\n",
    "import gzip\n",
    "import re\n",
    "\n",
    "sito_url = 'www.bestbuy.com'\n",
    "\n",
    "def AbsolutePaths(tags):\n",
    "    tmp=''\n",
    "    for tag in tags:\n",
    "        tmp+=tag.tag+'/'\n",
    "    return str(tmp)\n",
    "\n",
    "def load_gz(file):\n",
    "    #contiene come chiave il nome del file e come valore la pagina html\n",
    "    with gzip.open('dataset/'+ sito_url +'/pages/'+ file +'.gz', 'rb') as f:\n",
    "        file_content = f.read() #html\n",
    "    return file_content\n",
    "  \n",
    "def xpath_generator_gz(C): #C è una lista di liste [[nome.html, url], ... , ...]\n",
    "  X = []\n",
    "  for lista in C:\n",
    "    link = lista[1]\n",
    "    #carico la pagina html\n",
    "    html = load_gz(lista[0])\n",
    "    #analizza l'elemento html della pagina\n",
    "    tree = lxml.html.fromstring(html)\n",
    "    #ritorna la lista dei nodi foglia\n",
    "    childs = tree.xpath('//*[not(child::*)]')\n",
    "    #funzione che calcola il path assoluto radice-foglia come stringa\n",
    "    #calcolo della lista che contiene gli xpath assoluti alle foglie della pagina \n",
    "    for child in childs:\n",
    "      #ciascun elemento in X è una quadrupla (implementata come una lista di 4 elementi) formata da:\n",
    "      #url della pagina, xpath di ciascun nodo della pagina, contenuto del nodo, weight del nodo\n",
    "      xpath_element = []\n",
    "      tags = child.xpath('ancestor::node()')\n",
    "      path = AbsolutePaths(tags)\n",
    "      path += str(child.tag)\n",
    "      contenuto = child.text_content()\n",
    "      xpath_element.append(link)\n",
    "      xpath_element.append(path)\n",
    "      xpath_element.append(contenuto)\n",
    "      xpath_element.append(0)\n",
    "      X.append(xpath_element)\n",
    "  return X\n",
    "\n",
    "def xpath_generator(C): #C è una lista\n",
    "  X = []\n",
    "  for link in C:\n",
    "    #ritorna la get\n",
    "    link = ''.join(link)\n",
    "    link = link[:len(link)-1]    \n",
    "    response = requests.get(link)\n",
    "    #ritorna l'elemento html della pagina\n",
    "    tree = lxml.html.fromstring(response.text)\n",
    "    #ritorna la lista dei nodi foglia\n",
    "    childs = tree.xpath('//*[not(child::*)]')\n",
    "    #funzione che calcola il path assoluto radice-foglia come stringa\n",
    "    #calcolo della lista che contiene gli xpath assoluti alle foglie della pagina \n",
    "    for child in childs:\n",
    "      #ciascun elemento in X è una quadrupla (implementata come una lista di 4 elementi) formata da:\n",
    "      #url della pagina, xpath di ciascun nodo della pagina, contenuto del nodo, weight del nodo\n",
    "      xpath_element = []\n",
    "      tags = child.xpath('ancestor::node()')\n",
    "      path = AbsolutePaths(tags)\n",
    "      path += str(child.tag)\n",
    "      contenuto = child.text_content()\n",
    "      xpath_element.append(link)\n",
    "      xpath_element.append(path)\n",
    "      xpath_element.append(contenuto)\n",
    "      xpath_element.append(0)\n",
    "      X.append(xpath_element)\n",
    "  return X\n",
    "\n",
    "#Ricerca la frequency e la frequency del contenuto di un certo xpath\n",
    "#e la cardinalità dell'insieme di tutti i contenuti associati a quell'xpath\n",
    "def find_f(url, xpath, content, lista):\n",
    "  frequency = 1\n",
    "  f_content = 1\n",
    "  #t_i è l'insieme di tutti i contenuti associati a xpath\n",
    "  t_i = [content]\n",
    "  #lista dei url già visti nella ricerca\n",
    "  url_visti = []\n",
    "  url_visti.append(url)\n",
    "  for new_path in lista:\n",
    "    #se allo stesso xpath ho un contenuto diverso da quelli che già ho lo inserisco in t_i\n",
    "    if new_path[1] == xpath and new_path[2] not in t_i:\n",
    "      t_i.append(new_path[2])\n",
    "    #calcolo della frequency e di f_content\n",
    "    if new_path[0] not in url_visti:\n",
    "      if new_path[1] == xpath:\n",
    "        url_visti.append(new_path[0])\n",
    "        frequency += 1\n",
    "        if new_path[2] == content:\n",
    "          f_content += 1\n",
    "  return frequency, f_content, len(t_i)\n",
    "\n",
    "#lista = [(url,xpath,contenuto,weight), (....), (....), .... ]\n",
    "def weight_xpath(lista, num_pagine):\n",
    "  for xpath in lista:\n",
    "    #prendo xpath\n",
    "    x = xpath[1]\n",
    "    url = xpath[0]\n",
    "    contenuto = xpath[2]\n",
    "    #calcolo la frequency, la frequency del contenuto e la cardinalità di t_i\n",
    "    frequency, f_content, t_i = find_f(url, x, contenuto, lista)\n",
    "    #calcolo della informatività\n",
    "    info = 1 - (f_content / (num_pagine * t_i))\n",
    "    #calcolo del weight del xpath\n",
    "    weight = frequency * info\n",
    "    #inserisco il weight nella lista\n",
    "    xpath[3] = weight\n",
    "    \n",
    "def sum_weights_page(X):\n",
    "  url_weights = {}\n",
    "  for e in X:\n",
    "    k = e[0]\n",
    "    if k not in url_weights.keys():\n",
    "      url_weights[k] = e[3]\n",
    "    else:\n",
    "      url_weights[k] += e[3]\n",
    "  return url_weights\n",
    "\n",
    "#Trova la pagina (ritornando il suo url) che ha massima la somma dei weights di tutti i suoi xpath\n",
    "def find_p(X):\n",
    "  #creo un dizionario che ha come chiave l'url di una pagina e come valore la somma di tutti i weights dei suoi xpath\n",
    "  weighted_pages = sum_weights_page(X)\n",
    "  weight_max = 0\n",
    "  page_max = ''\n",
    "  #ricerco la pagina che ha valore massimo nel dizionario creato precedentemente\n",
    "  for k in weighted_pages.keys():\n",
    "    weight_page = weighted_pages[k]\n",
    "#     print(k, weight_page)\n",
    "    if weight_page > weight_max:\n",
    "      page_max = k\n",
    "      weight_max = weight_page\n",
    "#   print('\\n')\n",
    "  #ritorno l'url della pagina trovata\n",
    "  return page_max, weight_max\n",
    "\n",
    "#Crea un dizionario con chiave xpath e valore il contenuto\n",
    "def build_dict(X, p):\n",
    "  d = {}\n",
    "  for e in X:\n",
    "    if e[0] == p:\n",
    "      if e[1] not in d:\n",
    "        xpath = e[1]\n",
    "        content = e[2]\n",
    "        d[xpath] = content\n",
    "  return d\n",
    "\n",
    "#Rimuove la pagina da X e gli xpath associati ad essa\n",
    "def remove(X, p):\n",
    "  #nuova lista da riportare\n",
    "  X1 = []\n",
    "  dict_xpath_content = build_dict(X,p)\n",
    "  for e in X:\n",
    "    #se l'xpath è contenuto in una pagina diversa da p\n",
    "    #e ha un xpath non presente in p allora lo aggiungo a X1\n",
    "    if e[0] != p and e[1] not in dict_xpath_content:\n",
    "      X1.append(e)\n",
    "  return X1\n",
    "\n",
    "# ============= MAIN =============\n",
    "def page_annotation(C, K):\n",
    "  #X = xpath_generator(C)\n",
    "  start = time.time()\n",
    "  X = xpath_generator_gz(C)\n",
    "  print('XPath totali: ' + str(len(X)))\n",
    "  weight_xpath(X, len(C))\n",
    "  S = []\n",
    "  weights = []\n",
    "  while X != [] and len(S) <= K:      \n",
    "    p, weight = find_p(X)\n",
    "    S.append(p)\n",
    "    print(str(len(S))+'° ' + p + ' - weight: ' + str(weight) +'\\n')\n",
    "    weights.append(weight)\n",
    "    X = remove(X, p)\n",
    "  stop = time.time()\n",
    "  print(str((stop - start)/60) + ' min') #time\n",
    "  return S, X, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carico il dataset\n",
    "Il dataset preso in considerazione è quello di 'bestbuy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_url = []\n",
    "with open('dataset/'+ sito_url +'/_id2name.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        id_file = re.search('[0-9]+.html',line).group()\n",
    "        nome_url.append([id_file])\n",
    "i=0\n",
    "with open('dataset/'+ sito_url +'/_id2url.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        id_url = re.split('\\t', line)[1]\n",
    "        id_url = id_url.replace('\\n','')\n",
    "        lista = nome_url[i]\n",
    "        lista.append(id_url)\n",
    "        nome_url[i] = lista\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "primi100 = nome_url[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XPath totali: 58503\n",
      "1° http://www.bestbuy.com/site/lenovo-yoga-2-2-in-1-11-6-touch-screen-laptop-intel-pentium-4gb-memory-500gb-hard-drive-silver/3297045.p;jsessionid=3E6D02131286BB42249A70868018A3AC.bbolsp-app04-179?id=1219090034631&skuId=3297045&st=categoryid$abcat0502000&cp=1&lp=5 - Peso: 52656.73994846078\n",
      "\n",
      "2° http://www.bestbuy.com/site/asus-refurbished-11-6-vivobook-ultrabook-4-gb-memory-320-gb-hard-drive/1310162150.p;jsessionid=5589BBCFA01AE0FE136D3C99BD9A6CDC.bbolsp-app04-108?id=mp1310162150&skuId=1310162150&st=categoryid$abcat0502000&cp=22&lp=8#tab=buyingOptions - Peso: 691.6043571428571\n",
      "\n",
      "3° http://www.bestbuy.com/site/hp-15-6-elitebook-notebook-4-gb-memory-500-gb-hard-drive/1308851424.p;jsessionid=563D812A6BD53499E8AE0A33B4E10F88.bbolsp-app04-164?id=mp1308851424&skuId=1308851424&st=categoryid$pcmcat247400050000&cp=31&lp=13#tab=buyingOptions - Peso: 112.95960000000001\n",
      "\n",
      "4° http://www.bestbuy.com/site/dell-14-latitude-notebook-4-gb-memory/1311178471.p;jsessionid=14068F3B03018F7BF37BF73268C41800.bbolsp-app04-109?id=mp1311178471&skuId=1311178471&st=categoryid$pcmcat247400050000&cp=21&lp=13#tab=buyingOptions - Peso: 57.440000000000005\n",
      "\n",
      "5° http://www.bestbuy.com/site/toshiba-radius-2-in-1-15-6-touch-screen-laptop-intel-core-i7-8gb-memory-1tb-hard-drive-satin-gold/6129127.p;jsessionid=5CA2481E34F1ACF1823C5A6056C00A21.bbolsp-app04-185?id=1219191180245&skuId=6129127&st=categoryid$pcmcat247400050000&cp=3&lp=1 - Peso: 20.86\n",
      "\n",
      "6° http://www.bestbuy.com/site/asus-ultrabook-14-touch-screen-laptop-intel-core-i3-4gb-memory-500gb-hard-drive-black-silver/7683076.p;jsessionid=2FBD83481E62DB37B2D576AB4545B5B5.bbolsp-app04-136?id=1218858193072&skuId=7683076&st=categoryid$abcat0502000&cp=24&lp=7 - Peso: 9.5\n",
      "\n",
      "1909.0860612392426 sec\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "S, x, pesi = page_annotation(primi100,5)\n",
    "\n",
    "print('XPath rimanenti:',len(x)) #stampiamo il numero di xpath rimanenti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prove per le metriche dell'algoritmo\n",
    "precizion e recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
